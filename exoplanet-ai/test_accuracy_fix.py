#!/usr/bin/env python3
"""
Test pentru a verifica cÄƒ fix-ul calculului acurateÈ›ii funcÈ›ioneazÄƒ corect
"""

import pandas as pd
import numpy as np

# SimulÄƒm datele din screenshot
actual_data = {
    'CONFIRMED': 2315,
    'CANDIDATE': 1374, 
    'FALSE POSITIVE': 293
}

predicted_data = {
    'CONFIRMED': 2106,
    'CANDIDATE': 1577,
    'FALSE POSITIVE': 303
}

# SimulÄƒm predicÈ›ii realiste - unde majoritatea sunt corecte dar cu erori
np.random.seed(42)

# CreÄƒm date de test realiste
test_data = []

for class_name, actual_count in actual_data.items():
    # SimulÄƒm cÄƒ ~85% din predicÈ›ii sunt corecte pentru fiecare clasÄƒ
    correct_predictions = int(actual_count * 0.85)
    incorrect_predictions = actual_count - correct_predictions
    
    # AdÄƒugÄƒm predicÈ›iile corecte
    for _ in range(correct_predictions):
        test_data.append({
            'actual': class_name,
            'predicted': class_name
        })
    
    # AdÄƒugÄƒm predicÈ›iile incorecte (distribuite aleator cÄƒtre alte clase)
    other_classes = [c for c in actual_data.keys() if c != class_name]
    for _ in range(incorrect_predictions):
        wrong_class = np.random.choice(other_classes)
        test_data.append({
            'actual': class_name,
            'predicted': wrong_class
        })

# Convertim la DataFrame
df = pd.DataFrame(test_data)

# CalculÄƒm acurateÈ›ea pentru fiecare clasÄƒ (metoda corectÄƒ)
print("ğŸ” Test Calculul AcurateÈ›ii - Metoda CorectÄƒ")
print("=" * 60)

total_correct = 0
total_actual = 0

for class_name in actual_data.keys():
    # CÃ¢te instanÈ›e sunt de fapt din aceastÄƒ clasÄƒ
    actual_count = (df['actual'] == class_name).sum()
    
    # CÃ¢te dintre acestea au fost prezise corect
    correct_count = ((df['actual'] == class_name) & (df['predicted'] == class_name)).sum()
    
    # CÃ¢te au fost prezise ca fiind din aceastÄƒ clasÄƒ (indiferent de adevÄƒr)
    predicted_count = (df['predicted'] == class_name).sum()
    
    # Calculul corect al acurateÈ›ii
    accuracy = (correct_count / actual_count * 100) if actual_count > 0 else 0
    
    difference = predicted_count - actual_count
    diff_pct = (difference / actual_count * 100) if actual_count > 0 else 0
    
    print(f"{class_name:15} | Actual: {actual_count:4d} | Predicted: {predicted_count:4d} | "
          f"Correct: {correct_count:4d} | Accuracy: {accuracy:5.1f}% | Diff: {difference:+4d} ({diff_pct:+5.1f}%)")
    
    total_correct += correct_count
    total_actual += actual_count

# AcurateÈ›ea generalÄƒ
overall_accuracy = (total_correct / total_actual * 100) if total_actual > 0 else 0
print("-" * 60)
print(f"{'TOTAL':15} | Actual: {total_actual:4d} | Predicted: {len(df):4d} | "
      f"Correct: {total_correct:4d} | Accuracy: {overall_accuracy:5.1f}%")

print("\nâœ… ObservaÈ›ii:")
print(f"   â€¢ AcurateÈ›ea per clasÄƒ ar trebui sÄƒ fie ~85% (am simulat 85% corecte)")
print(f"   â€¢ AcurateÈ›ea totalÄƒ: {overall_accuracy:.1f}% (media ponderatÄƒ, NU suma)")
print(f"   â€¢ DiferenÈ›a aratÄƒ predicÈ›ii vs realitate, nu acurateÈ›ea")

print("\nğŸ¯ Testul aratÄƒ cÄƒ fix-ul este corect dacÄƒ:")
print("   â€¢ AcurateÈ›ea per clasÄƒ este rezonabilÄƒ (nu >90% cÃ¢nd diferenÈ›a e mare)")
print("   â€¢ AcurateÈ›ea totalÄƒ este o medie ponderatÄƒ, nu suma claselor")