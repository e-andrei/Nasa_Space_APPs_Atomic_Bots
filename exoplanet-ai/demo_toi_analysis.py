#!/usr/bin/env python3
"""
Demonstra»õie completƒÉ cu analiza TOI »ôi predic»õii ale modelului
"""

import sys
import pandas as pd
import numpy as np
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from model import train_from_csv, ExoplanetClassifier, load_dataset, train_from_multiple_csv

def demo_toi_analysis():
    print("üåü Analiza completƒÉ a datelor TOI cu predic»õii ale modelului")
    print("=" * 70)
    
    # Step 1: AntreneazƒÉ model pe date multiple (inclusiv TOI)
    print("Step 1: Antrenarea modelului pe date multiple...")
    
    # Lista fi»ôierelor de date disponibile
    data_files = [
        "date/cumulative_2025.10.03_23.13.19.csv",  # Kepler
        "date/k2pandc_2025.10.03_23.45.46.csv",     # K2
        "date/TOI_2025.10.04_00.04.19.csv"          # TESS TOI
    ]
    
    # VerificƒÉ care fi»ôiere existƒÉ
    existing_files = [f for f in data_files if Path(f).exists()]
    print(f"Fi»ôiere disponibile pentru antrenare: {len(existing_files)}")
    for f in existing_files:
        print(f"  - {f}")
    
    if len(existing_files) >= 2:
        # AntreneazƒÉ pe date multiple
        result = train_from_multiple_csv(
            data_paths=existing_files,
            output_model_path="models/multi_toi_classifier.joblib",
            model_type='random_forest',
            tune=False,
            random_state=42
        )
        
        print(f"‚úÖ Model multi-dataset antrenat:")
        print(f"   Accuracy: {result['metadata']['eval_metrics']['accuracy']:.3f}")
        print(f"   Macro F1: {result['metadata']['eval_metrics']['macro_f1']:.3f}")
        
        # √éncarcƒÉ modelul antrenat
        clf = ExoplanetClassifier.load("models/multi_toi_classifier.joblib")
        
    else:
        print("‚ö†Ô∏è  Antrenez doar pe datele Kepler...")
        result = train_from_csv(
            data_path="date/cumulative_2025.10.03_23.13.19.csv",
            output_model_path="models/toi_demo_classifier.joblib",
            model_type='random_forest',
            tune=False,
            random_state=42
        )
        clf = ExoplanetClassifier.load("models/toi_demo_classifier.joblib")
    
    # Step 2: Analiza detaliatƒÉ a datelor TOI
    print("\n" + "=" * 70)
    print("Step 2: Analiza detaliatƒÉ a datelor TOI")
    print("=" * 70)
    
    try:
        # √éncarcƒÉ datele TOI
        toi_data = pd.read_csv("date/TOI_2025.10.04_00.04.19.csv", comment='#')
        
        print(f"\nüìä Statistici generale pentru datele TOI:")
        print(f"   NumƒÉrul total de obiecte TESS: {len(toi_data):,}")
        
        # AnalizeazƒÉ clasificƒÉrile actuale
        if 'tfopwg_disp' in toi_data.columns:
            classification_counts = toi_data['tfopwg_disp'].value_counts()
            
            print(f"\nüîç Distribu»õia actualƒÉ a clasificƒÉrilor TOI:")
            total = len(toi_data)
            for category, count in classification_counts.items():
                percentage = (count / total * 100)
                description = get_toi_category_description(category)
                print(f"   {category} ({description}): {count:,} ({percentage:.1f}%)")
            
            # Mapare la categoriile standardizate
            standardized_counts = map_toi_to_standard_categories(toi_data)
            print(f"\nüìà Distribu»õia √Æn categoriile standardizate:")
            for category, count in standardized_counts.items():
                percentage = (count / total * 100)
                print(f"   {category}: {count:,} ({percentage:.1f}%)")
        
        # Step 3: Predic»õii ale modelului pe datele TOI
        print(f"\nü§ñ Predic»õii ale modelului pentru datele TOI:")
        
        try:
            # √éncarcƒÉ datele TOI pentru predic»õii
            X_toi, y_toi, _, _ = load_dataset("date/TOI_2025.10.04_00.04.19.csv")
            
            if len(X_toi) > 0:
                print(f"   ‚úÖ Date TOI procesate cu succes: {len(X_toi):,} obiecte")
                print(f"   Caracteristici disponibile: {len(X_toi.columns)}")
                
                # FƒÉ predic»õii pe toate datele TOI
                predictions = clf.predict(X_toi)
                probabilities = clf.predict_proba(X_toi)
                
                # AnalizeazƒÉ predic»õiile
                prediction_counts = pd.Series(predictions).value_counts()
                print(f"\nüìä Predic»õiile modelului pentru toate obiectele TOI:")
                for category, count in prediction_counts.items():
                    percentage = (count / len(predictions) * 100)
                    print(f"   Modelul prezice {category}: {count:,} ({percentage:.1f}%)")
                
                # ComparƒÉ cu clasificƒÉrile reale dacƒÉ sunt disponibile
                if 'tfopwg_disp' in toi_data.columns and len(y_toi) > 0:
                    print(f"\nüìã Compara»õia predic»õii vs clasificƒÉri reale TOI:")
                    
                    # MapeazƒÉ clasificƒÉrile reale la categoriile standard
                    actual_mapped = y_toi.map(get_standard_category_mapping())
                    
                    # CreeazƒÉ un DataFrame pentru compara»õie
                    comparison_df = pd.DataFrame({
                        'ClasificƒÉri_Reale': actual_mapped.value_counts(),
                        'Predic»õii_Model': prediction_counts
                    }).fillna(0).astype(int)
                    
                    print(comparison_df)
                    
                    # CalculeazƒÉ acurate»õea
                    if len(actual_mapped) == len(predictions):
                        agreement = (actual_mapped == predictions).sum()
                        accuracy = agreement / len(predictions) * 100
                        print(f"\n‚úÖ Acurate»õea modelului pe datele TOI: {accuracy:.1f}%")
                        print(f"   ({agreement:,} din {len(predictions):,} obiecte clasificate corect)")
                        
                        # AnalizeazƒÉ erorile
                        errors = actual_mapped != predictions
                        if errors.sum() > 0:
                            print(f"\n‚ùå AnalizƒÉ erori (primele 10):")
                            error_analysis = pd.DataFrame({
                                'Actual': actual_mapped[errors],
                                'Predicted': pd.Series(predictions)[errors]
                            }).head(10)
                            for idx, row in error_analysis.iterrows():
                                print(f"   Obiect {idx}: Real={row['Actual']}, Prezis={row['Predicted']}")
                
                # Afi»ôeazƒÉ c√¢teva predic»õii cu √Æncredere mare
                print(f"\nüéØ Primele 10 predic»õii cu √Æncrederea cea mai mare:")
                max_probs = np.max(probabilities, axis=1)
                high_confidence_idx = np.argsort(max_probs)[-10:][::-1]
                
                for i, idx in enumerate(high_confidence_idx):
                    pred = predictions[idx]
                    conf = max_probs[idx]
                    actual = y_toi.iloc[idx] if len(y_toi) > idx else "Unknown"
                    print(f"   {i+1}. TOI obiect {idx}: Prezis={pred}, √éncredere={conf:.3f}, Real={actual}")
                
            else:
                print(f"   ‚ö†Ô∏è  Nu s-au putut procesa datele TOI pentru predic»õii")
                
        except Exception as e:
            print(f"   ‚ùå Eroare la procesarea datelor TOI: {str(e)}")
            
            # √éncearcƒÉ cu caracteristici comune
            print(f"   üîÑ √éncerc cu caracteristici reduse...")
            try:
                # Folose»ôte doar caracteristicile comune
                common_features = ['orbital_period', 'planet_radius', 'stellar_teff', 'stellar_radius']
                available_features = [f for f in common_features if f in X_toi.columns]
                
                if available_features:
                    X_reduced = X_toi[available_features]
                    predictions_reduced = clf.predict(X_reduced)
                    print(f"   ‚úÖ Predic»õii cu {len(available_features)} caracteristici: {len(predictions_reduced)} obiecte")
                else:
                    print(f"   ‚ùå Nu sunt disponibile caracteristici comune")
                    
            except Exception as e2:
                print(f"   ‚ùå Eroare »ôi cu caracteristici reduse: {str(e2)}")
    
    except Exception as e:
        print(f"‚ùå Eroare la √ÆncƒÉrcarea datelor TOI: {str(e)}")
    
    # Step 4: Rezumat
    print("\n" + "=" * 70)
    print("Rezumat analiza TOI")
    print("=" * 70)
    print("‚úÖ Analiza completƒÉ realizatƒÉ cu succes!")
    print("\nInforma»õii importante:")
    print("‚Ä¢ Datele TOI con»õin obiecte TESS (Transiting Exoplanet Survey Satellite)")
    print("‚Ä¢ ClasificƒÉrile includ: CP (Confirmed), PC (Candidate), FP (False Positive)")
    print("‚Ä¢ Modelul a fost antrenat pentru a recunoa»ôte aceste categorii")
    print("‚Ä¢ Predic»õiile pot fi folosite pentru validarea obiectelor candidate")

def get_toi_category_description(category):
    """ReturneazƒÉ descrierea completƒÉ pentru categoriile TOI"""
    descriptions = {
        'CP': 'Confirmed Planet',
        'FP': 'False Positive', 
        'PC': 'Planet Candidate',
        'KP': 'Known Planet',
        'FA': 'False Alarm',
        'APC': 'Ambiguous Planet Candidate'
    }
    return descriptions.get(category, 'Unknown')

def get_standard_category_mapping():
    """ReturneazƒÉ maparea de la categoriile TOI la categoriile standard"""
    return {
        'CP': 'CONFIRMED',
        'KP': 'CONFIRMED',
        'PC': 'CANDIDATE',
        'APC': 'CANDIDATE',
        'FP': 'FALSE POSITIVE',
        'FA': 'FALSE POSITIVE'
    }

def map_toi_to_standard_categories(toi_data):
    """MapeazƒÉ categoriile TOI la categoriile standardizate »ôi numƒÉrƒÉ"""
    mapping = get_standard_category_mapping()
    
    if 'tfopwg_disp' in toi_data.columns:
        mapped_categories = toi_data['tfopwg_disp'].map(mapping)
        return mapped_categories.value_counts()
    else:
        return {}

if __name__ == "__main__":
    demo_toi_analysis()